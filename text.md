An autonomous vehicle can sense its environment and operate without human involvement, and its management in an intelligent transportation system could significantly reduce traffic congestion and overall travel time in a network. This article proposes an Adaptive Traffic Signal Controller (ATSC) using State-Action-Reward-State-Action (SARSA ($\lambda$)), based on multi-agent Q-Learning techniques to manage autonomous vehicles within an urban area. Therefore, it introduces a Gaussian function to effectively regulate the eligibility trace vector's decay mechanism. On the other hand, an efficient understanding of the state of the traffic environment is crucial for an agent to take optimal actions. However, the conventional models feed the state values to the agents through the MinMax normalisation technique, which shows less efficiency in some cases. This research found the effectiveness of standard and MaxAbs scaled state values instead of MinMax.
Furthermore, the combination of the A-star routing algorithm and proposed model demonstrated a tremendous increase in performance compared to the conventional SARSA ($\lambda$)-based routing algorithms. The developed experimental study based on microscopic traffic simulation in the SUMO package helped to evaluate the performance of the proposed traffic signal controller and routing algorithms. The results showed a reduction of the vehicles' average total waiting time and total stops by a mean value of $59.9$\% and $17.55$\% relative to the considered baselines. Additionally, the A-star combined with the proposed controller outperformed the conventional approaches by increasing the average trip speed by $3.4$\%.
